<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>ChatGPT Plugins原理介绍和讨论 | DawsonChen&#39;s Blog</title>
<meta name="keywords" content="">
<meta name="description" content="背景 让我们回顾以下过去的半个月里重要的AI发展。
事件 时间 介绍 公司 Visual ChatGPT 3-12 可以通过文本和图片聊天，甚至修改图片内容。 Microsoft GPT4发布 3-13 更大的ChatGPT模型，部分专业能力达到人类水平，可以接收图片输入。 OpenAI 365 Copilot 3-16 智能办公大杀器。 Microsoft 文心一言 3-16 中国版的ChatGPT Baidu ChatGPT plugin 3-23 可以使用工具的ChatGPT OpenAI HuggingGPT 3-30 可以使用HuggingFace中模型能力的ChatGPT Microsoft 很多评价说过去的几周是AI发展的Crazy Week，这种速度疯狂到甚至让人们开始担心AI会影响到社会和人类，并在公开信中呼吁暂停AI的研究。造成这种现象的原因可以理解为，一是基于ChatGPT的成功，二是行业内大量的关注。
个人认为，这其中ChatGPT plugin可以认为是对行业应用最有影响力的一个技术，也是继ChatGPT发布以来OpenAI发布的最重要的更新，可以简单的理解为OpenAI发布了对应ChatGPT的应用商店。对未来人工智能应用的形态也有一定启发，以前的AI模型的定位更多的是充当的一个单一的智能工具，具体到某个任务上，还需要人工协同才能完成；但是有了plugin这项技术，那么AI模型可以代替之前人工的部分，自主使用工具，从而端到端的完成某一项任务。这也是为什么一些基础的工作岗位很有可能会被新一代AI技术取代。
在网上已经有很多对ChatGPT plugin如何使用的介绍，但是比较少有对其实现原理进行解析的内容。这篇文章里我们主要分析一下它的原理，以及可能造成的影响。
必要性 首先说为什么语言模型要使用插件？随着语言模型的规模不断变大，各种涌现能力被相继发现，从而衍生出各种关于模型能力的研究。但谈到语言模型的应用，始终绕不开一个问题，就是模型无法获取外界的信息。也就是，一旦模型训练完成，后续的所有输出都来自于训练数据中学习到的知识。
大语言模型存在的问题可以总结为以下2点：
缺少最新数据的补充；
在不同的应用场景，对数据的需求也是不同的。在开放问答领域，可以是维基百科一类的数据。在特定业务领域，可能是公司内部的一些私人数据集。
缺少专业的能力；
大型语言模型对通用逻辑的理解是比较好的，比方说写一篇文章，与人聊天。但是涉及到特殊的专业，比方说作数学题、求公式的解，这类型问题对模型来说是有点难的。
虽然GPT4号称用了更大的模型，可以在一些专业领域得到类似于人类的效果甚至超越。但是从本质上来看，语言模型所采用的文字接龙训练方式，对于这类问题是非常不友好的。
或许随着模型变大，训练时间更长可以得到更好的效果，但是花费巨大训练出的GPT3在计算能力上远远达不到1970年代出现的计算器，本身就可以说明大模型技术是不足以解决专业推理问题的。
了解了以上模型存在的问题，就可以理解教模型使用插件的必要性了。PS：使用插件、使用工具，在不同的地方有不同的说法，但是是一件事情。
模型使用工具技术发展 在GPT3发布以后，就有一些AI模型使用插件的技术研究陆续出现，甚至有一些开源的框架在github上收获不错的关注。
想法的提出：MRKL System MRKL System（全名是Modular Reasoning, Knowledge and Language，论文链接，博客链接）由以色列的一家人工智能公司AI21推出，可以被认为是语言模型使用工具系统想法的提出者。虽然在此之前有WebGPT这类教模型使用浏览器的工作，但它是第一个提出将模型作为中枢，接入各种不同类型的插件来完成任务的工作。
从工作流程上来看，MRKL已经完全接近于ChatGPT plugin。MRKL认为这是一种跨越神经学派和符号学派的架构（neuro-symbolic architecture），各种插件可以被认为是符号系统，由神经学派的语言模型进行统一调用。
这篇论文中以使用计算器为例子，主要描述了如何将自然语言中的内容转换为API所需要的参数，文中提出语言模型few-shot在复杂的问题上性能有限，所以用Prompt tuning这种轻量化的微调技术提升转换的准确率。Prompt tuning技术是用特定训练好的非自然语言prompt来控制模型在特定任务中的生成表现，对应到MRKL中那就是每一个插件都需要训练一个特定的Prompt，虽然说有一定训练成本，但也算是一种比较好的解决思路。
可是文中对于最重要的问题：”怎么决定调用插件？“，这块的细节并没有太多的描述，也引出了关于大模型推理技术的发展。
Reasoning技术：ReACT 为了教会模型实用工具，一种方法是首先让模型具备推理的能力，从而能够模拟人使用工具的过程。应该说语言模型的训练方式和推理是不沾边的，但是语言模型的美妙之处就在于，当模型大小足够大的时候，它会诞生出很多出乎意料的能力，比方说推理能力。
大语言模型的推理能力通过Chain-of-thought体现出来，但是这种推理能力需要显式的Prompt进行引导。根据引导方式的不同产生出各种不同的技术，其本质上是对不同思维方式的模拟，这里我们只介绍比较典型的ReACT技术。
ReACT用强化学习的方式建模推理的过程，agent认为是一个可以使用各种工具的智能体，environment为所有可用插件构成的工具箱集合，action为可以使用的插件功能集合。而控制策略为语言模型中学习到的知识。一个典型的推理的流程如下图所示：">
<meta name="author" content="Dawson Chen">
<link rel="canonical" href="http://localhost:1313/posts/chatgpt-plugin/">
<meta name="google-site-verification" content="XYZabc">
<meta name="yandex-verification" content="XYZabc">
<meta name="msvalidate.01" content="XYZabc"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  <meta name="referrer" content="no-referrer-when-downgrade">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/posts/chatgpt-plugin/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.css"
    integrity="sha384-bYdxxUwYipFNohQlHt0bjN/LCpueqWz13HufFEV1SUatKs1cm4L6fFgCi1jT643X" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.js"
    integrity="sha384-Qsn9KnoKISj6dI8g7p1HBlNpVx0I8p1SvlwOldgi3IorMle61nQy4zEahWYtljaz"
    crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/auto-render.min.js"
    integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05"
    crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        renderMathInElement(document.body, {
            
            
            delimiters: [
                { left: '$$', right: '$$', display: true },
                { left: '$', right: '$', display: false },
                { left: '\\(', right: '\\)', display: false },
                { left: '\\[', right: '\\]', display: true }
            ],
            
            throwOnError: false
        });
    });
</script>



<script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
<script>

const config = {
    startOnLoad:true,
    theme: 'forest',
    themeVariables: {
        lineColor: "#fafafa"    
    },
    flowchart: {
        useMaxWidth:false,
        htmlLabels:true
        }
};
mermaid.initialize(config);


window.onload = () => {
    window.mermaid.init(undefined, document.querySelectorAll('.language-mermaid'));
}
</script><meta property="og:title" content="ChatGPT Plugins原理介绍和讨论" />
<meta property="og:description" content="背景 让我们回顾以下过去的半个月里重要的AI发展。
事件 时间 介绍 公司 Visual ChatGPT 3-12 可以通过文本和图片聊天，甚至修改图片内容。 Microsoft GPT4发布 3-13 更大的ChatGPT模型，部分专业能力达到人类水平，可以接收图片输入。 OpenAI 365 Copilot 3-16 智能办公大杀器。 Microsoft 文心一言 3-16 中国版的ChatGPT Baidu ChatGPT plugin 3-23 可以使用工具的ChatGPT OpenAI HuggingGPT 3-30 可以使用HuggingFace中模型能力的ChatGPT Microsoft 很多评价说过去的几周是AI发展的Crazy Week，这种速度疯狂到甚至让人们开始担心AI会影响到社会和人类，并在公开信中呼吁暂停AI的研究。造成这种现象的原因可以理解为，一是基于ChatGPT的成功，二是行业内大量的关注。
个人认为，这其中ChatGPT plugin可以认为是对行业应用最有影响力的一个技术，也是继ChatGPT发布以来OpenAI发布的最重要的更新，可以简单的理解为OpenAI发布了对应ChatGPT的应用商店。对未来人工智能应用的形态也有一定启发，以前的AI模型的定位更多的是充当的一个单一的智能工具，具体到某个任务上，还需要人工协同才能完成；但是有了plugin这项技术，那么AI模型可以代替之前人工的部分，自主使用工具，从而端到端的完成某一项任务。这也是为什么一些基础的工作岗位很有可能会被新一代AI技术取代。
在网上已经有很多对ChatGPT plugin如何使用的介绍，但是比较少有对其实现原理进行解析的内容。这篇文章里我们主要分析一下它的原理，以及可能造成的影响。
必要性 首先说为什么语言模型要使用插件？随着语言模型的规模不断变大，各种涌现能力被相继发现，从而衍生出各种关于模型能力的研究。但谈到语言模型的应用，始终绕不开一个问题，就是模型无法获取外界的信息。也就是，一旦模型训练完成，后续的所有输出都来自于训练数据中学习到的知识。
大语言模型存在的问题可以总结为以下2点：
缺少最新数据的补充；
在不同的应用场景，对数据的需求也是不同的。在开放问答领域，可以是维基百科一类的数据。在特定业务领域，可能是公司内部的一些私人数据集。
缺少专业的能力；
大型语言模型对通用逻辑的理解是比较好的，比方说写一篇文章，与人聊天。但是涉及到特殊的专业，比方说作数学题、求公式的解，这类型问题对模型来说是有点难的。
虽然GPT4号称用了更大的模型，可以在一些专业领域得到类似于人类的效果甚至超越。但是从本质上来看，语言模型所采用的文字接龙训练方式，对于这类问题是非常不友好的。
或许随着模型变大，训练时间更长可以得到更好的效果，但是花费巨大训练出的GPT3在计算能力上远远达不到1970年代出现的计算器，本身就可以说明大模型技术是不足以解决专业推理问题的。
了解了以上模型存在的问题，就可以理解教模型使用插件的必要性了。PS：使用插件、使用工具，在不同的地方有不同的说法，但是是一件事情。
模型使用工具技术发展 在GPT3发布以后，就有一些AI模型使用插件的技术研究陆续出现，甚至有一些开源的框架在github上收获不错的关注。
想法的提出：MRKL System MRKL System（全名是Modular Reasoning, Knowledge and Language，论文链接，博客链接）由以色列的一家人工智能公司AI21推出，可以被认为是语言模型使用工具系统想法的提出者。虽然在此之前有WebGPT这类教模型使用浏览器的工作，但它是第一个提出将模型作为中枢，接入各种不同类型的插件来完成任务的工作。
从工作流程上来看，MRKL已经完全接近于ChatGPT plugin。MRKL认为这是一种跨越神经学派和符号学派的架构（neuro-symbolic architecture），各种插件可以被认为是符号系统，由神经学派的语言模型进行统一调用。
这篇论文中以使用计算器为例子，主要描述了如何将自然语言中的内容转换为API所需要的参数，文中提出语言模型few-shot在复杂的问题上性能有限，所以用Prompt tuning这种轻量化的微调技术提升转换的准确率。Prompt tuning技术是用特定训练好的非自然语言prompt来控制模型在特定任务中的生成表现，对应到MRKL中那就是每一个插件都需要训练一个特定的Prompt，虽然说有一定训练成本，但也算是一种比较好的解决思路。
可是文中对于最重要的问题：”怎么决定调用插件？“，这块的细节并没有太多的描述，也引出了关于大模型推理技术的发展。
Reasoning技术：ReACT 为了教会模型实用工具，一种方法是首先让模型具备推理的能力，从而能够模拟人使用工具的过程。应该说语言模型的训练方式和推理是不沾边的，但是语言模型的美妙之处就在于，当模型大小足够大的时候，它会诞生出很多出乎意料的能力，比方说推理能力。
大语言模型的推理能力通过Chain-of-thought体现出来，但是这种推理能力需要显式的Prompt进行引导。根据引导方式的不同产生出各种不同的技术，其本质上是对不同思维方式的模拟，这里我们只介绍比较典型的ReACT技术。
ReACT用强化学习的方式建模推理的过程，agent认为是一个可以使用各种工具的智能体，environment为所有可用插件构成的工具箱集合，action为可以使用的插件功能集合。而控制策略为语言模型中学习到的知识。一个典型的推理的流程如下图所示：" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/posts/chatgpt-plugin/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-04-07T20:43:43+08:00" />
<meta property="article:modified_time" content="2023-04-07T20:43:43+08:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="ChatGPT Plugins原理介绍和讨论"/>
<meta name="twitter:description" content="背景 让我们回顾以下过去的半个月里重要的AI发展。
事件 时间 介绍 公司 Visual ChatGPT 3-12 可以通过文本和图片聊天，甚至修改图片内容。 Microsoft GPT4发布 3-13 更大的ChatGPT模型，部分专业能力达到人类水平，可以接收图片输入。 OpenAI 365 Copilot 3-16 智能办公大杀器。 Microsoft 文心一言 3-16 中国版的ChatGPT Baidu ChatGPT plugin 3-23 可以使用工具的ChatGPT OpenAI HuggingGPT 3-30 可以使用HuggingFace中模型能力的ChatGPT Microsoft 很多评价说过去的几周是AI发展的Crazy Week，这种速度疯狂到甚至让人们开始担心AI会影响到社会和人类，并在公开信中呼吁暂停AI的研究。造成这种现象的原因可以理解为，一是基于ChatGPT的成功，二是行业内大量的关注。
个人认为，这其中ChatGPT plugin可以认为是对行业应用最有影响力的一个技术，也是继ChatGPT发布以来OpenAI发布的最重要的更新，可以简单的理解为OpenAI发布了对应ChatGPT的应用商店。对未来人工智能应用的形态也有一定启发，以前的AI模型的定位更多的是充当的一个单一的智能工具，具体到某个任务上，还需要人工协同才能完成；但是有了plugin这项技术，那么AI模型可以代替之前人工的部分，自主使用工具，从而端到端的完成某一项任务。这也是为什么一些基础的工作岗位很有可能会被新一代AI技术取代。
在网上已经有很多对ChatGPT plugin如何使用的介绍，但是比较少有对其实现原理进行解析的内容。这篇文章里我们主要分析一下它的原理，以及可能造成的影响。
必要性 首先说为什么语言模型要使用插件？随着语言模型的规模不断变大，各种涌现能力被相继发现，从而衍生出各种关于模型能力的研究。但谈到语言模型的应用，始终绕不开一个问题，就是模型无法获取外界的信息。也就是，一旦模型训练完成，后续的所有输出都来自于训练数据中学习到的知识。
大语言模型存在的问题可以总结为以下2点：
缺少最新数据的补充；
在不同的应用场景，对数据的需求也是不同的。在开放问答领域，可以是维基百科一类的数据。在特定业务领域，可能是公司内部的一些私人数据集。
缺少专业的能力；
大型语言模型对通用逻辑的理解是比较好的，比方说写一篇文章，与人聊天。但是涉及到特殊的专业，比方说作数学题、求公式的解，这类型问题对模型来说是有点难的。
虽然GPT4号称用了更大的模型，可以在一些专业领域得到类似于人类的效果甚至超越。但是从本质上来看，语言模型所采用的文字接龙训练方式，对于这类问题是非常不友好的。
或许随着模型变大，训练时间更长可以得到更好的效果，但是花费巨大训练出的GPT3在计算能力上远远达不到1970年代出现的计算器，本身就可以说明大模型技术是不足以解决专业推理问题的。
了解了以上模型存在的问题，就可以理解教模型使用插件的必要性了。PS：使用插件、使用工具，在不同的地方有不同的说法，但是是一件事情。
模型使用工具技术发展 在GPT3发布以后，就有一些AI模型使用插件的技术研究陆续出现，甚至有一些开源的框架在github上收获不错的关注。
想法的提出：MRKL System MRKL System（全名是Modular Reasoning, Knowledge and Language，论文链接，博客链接）由以色列的一家人工智能公司AI21推出，可以被认为是语言模型使用工具系统想法的提出者。虽然在此之前有WebGPT这类教模型使用浏览器的工作，但它是第一个提出将模型作为中枢，接入各种不同类型的插件来完成任务的工作。
从工作流程上来看，MRKL已经完全接近于ChatGPT plugin。MRKL认为这是一种跨越神经学派和符号学派的架构（neuro-symbolic architecture），各种插件可以被认为是符号系统，由神经学派的语言模型进行统一调用。
这篇论文中以使用计算器为例子，主要描述了如何将自然语言中的内容转换为API所需要的参数，文中提出语言模型few-shot在复杂的问题上性能有限，所以用Prompt tuning这种轻量化的微调技术提升转换的准确率。Prompt tuning技术是用特定训练好的非自然语言prompt来控制模型在特定任务中的生成表现，对应到MRKL中那就是每一个插件都需要训练一个特定的Prompt，虽然说有一定训练成本，但也算是一种比较好的解决思路。
可是文中对于最重要的问题：”怎么决定调用插件？“，这块的细节并没有太多的描述，也引出了关于大模型推理技术的发展。
Reasoning技术：ReACT 为了教会模型实用工具，一种方法是首先让模型具备推理的能力，从而能够模拟人使用工具的过程。应该说语言模型的训练方式和推理是不沾边的，但是语言模型的美妙之处就在于，当模型大小足够大的时候，它会诞生出很多出乎意料的能力，比方说推理能力。
大语言模型的推理能力通过Chain-of-thought体现出来，但是这种推理能力需要显式的Prompt进行引导。根据引导方式的不同产生出各种不同的技术，其本质上是对不同思维方式的模拟，这里我们只介绍比较典型的ReACT技术。
ReACT用强化学习的方式建模推理的过程，agent认为是一个可以使用各种工具的智能体，environment为所有可用插件构成的工具箱集合，action为可以使用的插件功能集合。而控制策略为语言模型中学习到的知识。一个典型的推理的流程如下图所示："/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "http://localhost:1313/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "ChatGPT Plugins原理介绍和讨论",
      "item": "http://localhost:1313/posts/chatgpt-plugin/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "ChatGPT Plugins原理介绍和讨论",
  "name": "ChatGPT Plugins原理介绍和讨论",
  "description": "背景 让我们回顾以下过去的半个月里重要的AI发展。\n事件 时间 介绍 公司 Visual ChatGPT 3-12 可以通过文本和图片聊天，甚至修改图片内容。 Microsoft GPT4发布 3-13 更大的ChatGPT模型，部分专业能力达到人类水平，可以接收图片输入。 OpenAI 365 Copilot 3-16 智能办公大杀器。 Microsoft 文心一言 3-16 中国版的ChatGPT Baidu ChatGPT plugin 3-23 可以使用工具的ChatGPT OpenAI HuggingGPT 3-30 可以使用HuggingFace中模型能力的ChatGPT Microsoft 很多评价说过去的几周是AI发展的Crazy Week，这种速度疯狂到甚至让人们开始担心AI会影响到社会和人类，并在公开信中呼吁暂停AI的研究。造成这种现象的原因可以理解为，一是基于ChatGPT的成功，二是行业内大量的关注。\n个人认为，这其中ChatGPT plugin可以认为是对行业应用最有影响力的一个技术，也是继ChatGPT发布以来OpenAI发布的最重要的更新，可以简单的理解为OpenAI发布了对应ChatGPT的应用商店。对未来人工智能应用的形态也有一定启发，以前的AI模型的定位更多的是充当的一个单一的智能工具，具体到某个任务上，还需要人工协同才能完成；但是有了plugin这项技术，那么AI模型可以代替之前人工的部分，自主使用工具，从而端到端的完成某一项任务。这也是为什么一些基础的工作岗位很有可能会被新一代AI技术取代。\n在网上已经有很多对ChatGPT plugin如何使用的介绍，但是比较少有对其实现原理进行解析的内容。这篇文章里我们主要分析一下它的原理，以及可能造成的影响。\n必要性 首先说为什么语言模型要使用插件？随着语言模型的规模不断变大，各种涌现能力被相继发现，从而衍生出各种关于模型能力的研究。但谈到语言模型的应用，始终绕不开一个问题，就是模型无法获取外界的信息。也就是，一旦模型训练完成，后续的所有输出都来自于训练数据中学习到的知识。\n大语言模型存在的问题可以总结为以下2点：\n缺少最新数据的补充；\n在不同的应用场景，对数据的需求也是不同的。在开放问答领域，可以是维基百科一类的数据。在特定业务领域，可能是公司内部的一些私人数据集。\n缺少专业的能力；\n大型语言模型对通用逻辑的理解是比较好的，比方说写一篇文章，与人聊天。但是涉及到特殊的专业，比方说作数学题、求公式的解，这类型问题对模型来说是有点难的。\n虽然GPT4号称用了更大的模型，可以在一些专业领域得到类似于人类的效果甚至超越。但是从本质上来看，语言模型所采用的文字接龙训练方式，对于这类问题是非常不友好的。\n或许随着模型变大，训练时间更长可以得到更好的效果，但是花费巨大训练出的GPT3在计算能力上远远达不到1970年代出现的计算器，本身就可以说明大模型技术是不足以解决专业推理问题的。\n了解了以上模型存在的问题，就可以理解教模型使用插件的必要性了。PS：使用插件、使用工具，在不同的地方有不同的说法，但是是一件事情。\n模型使用工具技术发展 在GPT3发布以后，就有一些AI模型使用插件的技术研究陆续出现，甚至有一些开源的框架在github上收获不错的关注。\n想法的提出：MRKL System MRKL System（全名是Modular Reasoning, Knowledge and Language，论文链接，博客链接）由以色列的一家人工智能公司AI21推出，可以被认为是语言模型使用工具系统想法的提出者。虽然在此之前有WebGPT这类教模型使用浏览器的工作，但它是第一个提出将模型作为中枢，接入各种不同类型的插件来完成任务的工作。\n从工作流程上来看，MRKL已经完全接近于ChatGPT plugin。MRKL认为这是一种跨越神经学派和符号学派的架构（neuro-symbolic architecture），各种插件可以被认为是符号系统，由神经学派的语言模型进行统一调用。\n这篇论文中以使用计算器为例子，主要描述了如何将自然语言中的内容转换为API所需要的参数，文中提出语言模型few-shot在复杂的问题上性能有限，所以用Prompt tuning这种轻量化的微调技术提升转换的准确率。Prompt tuning技术是用特定训练好的非自然语言prompt来控制模型在特定任务中的生成表现，对应到MRKL中那就是每一个插件都需要训练一个特定的Prompt，虽然说有一定训练成本，但也算是一种比较好的解决思路。\n可是文中对于最重要的问题：”怎么决定调用插件？“，这块的细节并没有太多的描述，也引出了关于大模型推理技术的发展。\nReasoning技术：ReACT 为了教会模型实用工具，一种方法是首先让模型具备推理的能力，从而能够模拟人使用工具的过程。应该说语言模型的训练方式和推理是不沾边的，但是语言模型的美妙之处就在于，当模型大小足够大的时候，它会诞生出很多出乎意料的能力，比方说推理能力。\n大语言模型的推理能力通过Chain-of-thought体现出来，但是这种推理能力需要显式的Prompt进行引导。根据引导方式的不同产生出各种不同的技术，其本质上是对不同思维方式的模拟，这里我们只介绍比较典型的ReACT技术。\nReACT用强化学习的方式建模推理的过程，agent认为是一个可以使用各种工具的智能体，environment为所有可用插件构成的工具箱集合，action为可以使用的插件功能集合。而控制策略为语言模型中学习到的知识。一个典型的推理的流程如下图所示：",
  "keywords": [
    
  ],
  "articleBody": "背景 让我们回顾以下过去的半个月里重要的AI发展。\n事件 时间 介绍 公司 Visual ChatGPT 3-12 可以通过文本和图片聊天，甚至修改图片内容。 Microsoft GPT4发布 3-13 更大的ChatGPT模型，部分专业能力达到人类水平，可以接收图片输入。 OpenAI 365 Copilot 3-16 智能办公大杀器。 Microsoft 文心一言 3-16 中国版的ChatGPT Baidu ChatGPT plugin 3-23 可以使用工具的ChatGPT OpenAI HuggingGPT 3-30 可以使用HuggingFace中模型能力的ChatGPT Microsoft 很多评价说过去的几周是AI发展的Crazy Week，这种速度疯狂到甚至让人们开始担心AI会影响到社会和人类，并在公开信中呼吁暂停AI的研究。造成这种现象的原因可以理解为，一是基于ChatGPT的成功，二是行业内大量的关注。\n个人认为，这其中ChatGPT plugin可以认为是对行业应用最有影响力的一个技术，也是继ChatGPT发布以来OpenAI发布的最重要的更新，可以简单的理解为OpenAI发布了对应ChatGPT的应用商店。对未来人工智能应用的形态也有一定启发，以前的AI模型的定位更多的是充当的一个单一的智能工具，具体到某个任务上，还需要人工协同才能完成；但是有了plugin这项技术，那么AI模型可以代替之前人工的部分，自主使用工具，从而端到端的完成某一项任务。这也是为什么一些基础的工作岗位很有可能会被新一代AI技术取代。\n在网上已经有很多对ChatGPT plugin如何使用的介绍，但是比较少有对其实现原理进行解析的内容。这篇文章里我们主要分析一下它的原理，以及可能造成的影响。\n必要性 首先说为什么语言模型要使用插件？随着语言模型的规模不断变大，各种涌现能力被相继发现，从而衍生出各种关于模型能力的研究。但谈到语言模型的应用，始终绕不开一个问题，就是模型无法获取外界的信息。也就是，一旦模型训练完成，后续的所有输出都来自于训练数据中学习到的知识。\n大语言模型存在的问题可以总结为以下2点：\n缺少最新数据的补充；\n在不同的应用场景，对数据的需求也是不同的。在开放问答领域，可以是维基百科一类的数据。在特定业务领域，可能是公司内部的一些私人数据集。\n缺少专业的能力；\n大型语言模型对通用逻辑的理解是比较好的，比方说写一篇文章，与人聊天。但是涉及到特殊的专业，比方说作数学题、求公式的解，这类型问题对模型来说是有点难的。\n虽然GPT4号称用了更大的模型，可以在一些专业领域得到类似于人类的效果甚至超越。但是从本质上来看，语言模型所采用的文字接龙训练方式，对于这类问题是非常不友好的。\n或许随着模型变大，训练时间更长可以得到更好的效果，但是花费巨大训练出的GPT3在计算能力上远远达不到1970年代出现的计算器，本身就可以说明大模型技术是不足以解决专业推理问题的。\n了解了以上模型存在的问题，就可以理解教模型使用插件的必要性了。PS：使用插件、使用工具，在不同的地方有不同的说法，但是是一件事情。\n模型使用工具技术发展 在GPT3发布以后，就有一些AI模型使用插件的技术研究陆续出现，甚至有一些开源的框架在github上收获不错的关注。\n想法的提出：MRKL System MRKL System（全名是Modular Reasoning, Knowledge and Language，论文链接，博客链接）由以色列的一家人工智能公司AI21推出，可以被认为是语言模型使用工具系统想法的提出者。虽然在此之前有WebGPT这类教模型使用浏览器的工作，但它是第一个提出将模型作为中枢，接入各种不同类型的插件来完成任务的工作。\n从工作流程上来看，MRKL已经完全接近于ChatGPT plugin。MRKL认为这是一种跨越神经学派和符号学派的架构（neuro-symbolic architecture），各种插件可以被认为是符号系统，由神经学派的语言模型进行统一调用。\n这篇论文中以使用计算器为例子，主要描述了如何将自然语言中的内容转换为API所需要的参数，文中提出语言模型few-shot在复杂的问题上性能有限，所以用Prompt tuning这种轻量化的微调技术提升转换的准确率。Prompt tuning技术是用特定训练好的非自然语言prompt来控制模型在特定任务中的生成表现，对应到MRKL中那就是每一个插件都需要训练一个特定的Prompt，虽然说有一定训练成本，但也算是一种比较好的解决思路。\n可是文中对于最重要的问题：”怎么决定调用插件？“，这块的细节并没有太多的描述，也引出了关于大模型推理技术的发展。\nReasoning技术：ReACT 为了教会模型实用工具，一种方法是首先让模型具备推理的能力，从而能够模拟人使用工具的过程。应该说语言模型的训练方式和推理是不沾边的，但是语言模型的美妙之处就在于，当模型大小足够大的时候，它会诞生出很多出乎意料的能力，比方说推理能力。\n大语言模型的推理能力通过Chain-of-thought体现出来，但是这种推理能力需要显式的Prompt进行引导。根据引导方式的不同产生出各种不同的技术，其本质上是对不同思维方式的模拟，这里我们只介绍比较典型的ReACT技术。\nReACT用强化学习的方式建模推理的过程，agent认为是一个可以使用各种工具的智能体，environment为所有可用插件构成的工具箱集合，action为可以使用的插件功能集合。而控制策略为语言模型中学习到的知识。一个典型的推理的流程如下图所示：\nReACT推理流程可以分为Thought→Action→Observation→Thought 这样的循环，具体如何实现在本文的后续内容中会进行分析。\n使用工具的语言模型：Toolformer 与利用推理能力使用工具的思路不同，Toolformer是在训练语言模型过程中，使模型学习在适当位置调用相关API，并用API结果辅助后续的文本生成。在Toolformer训练过程中，数据是Pittsburgh is also known as [QA(What …?→ Steel City)] the Steel City.这种格式，如果是人去标注数据，首先需要找到API的放置位置，判断标准是API结果对后续文本生成有帮助，并且上文中有API需要的参数；然后是将API的标识、输入、输出以[QA(What …?→ Steel City)]这种形式插入到训练文本中。\n注意，模型训练仍然采用典型的文字接龙方式，所以对原本语言模型的能力并没有损失。论文中提出一种利用LLM去自动标注这种数据的方式，和远程监督类似，步骤如下图：\n工具提出：LangChain LangChain差不多是在2022年底提出的，那时候也是LLMs技术急剧发展的阶段。其核心是做一个基于LLMs的工具，基本上所有需要用LLMs实现的功能都可以在里面找到对应的工具。其中一个主要的能力，就是教会模型使用工具，并且接入方式和扩展性都非常好。除此之外还有很多好用的工具，比如：Prompt管理、Memory。名字中的Chain表示其核心设计思路是将不同的模块链接在一起。\n详细的文档见链接。\nhttps://github.com/hwchase17/langchain\nLangChain中有很多有用的工具，包括各种搜索引擎Bing、Google、SerpAPI（google问答）、wiki等。还有一个更有趣的是Human as a tool插件，可以使语言模型必要时询问人类，从而模拟各种各样的功能。\n在原理部分我们会介绍它的工作流程。\nChatGPT plugin的原理 ChatGPT plugin是作为一个产品发布的，并且功能还没有完全开放，因此其实现原理细节也不是很清楚。但是由于LangChain中已经实现了类似的功能，并且2者的发布时间比较相近，所以有理由相信2者在原理上是有相似的。\n下面我们分2部分，首先分析LangChain中使用工具的原理；第二部分通过比较2者的区别，得出一些关于ChatGPT plugin原理的猜想。\nLangChain的工作流程 首先让我们看一个例子：\nfrom langchain.agents import load_tools from langchain.agents import initialize_agent from langchain.llms import OpenAI llm = OpenAI(temperature=0) tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm) agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True) response = agent.run(\"Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?\") 代码里涉及到的关键概念：\nllm: BaseLLM\nLangChain中对一系列开源模型接口的封装，其主要作用是统一不同的模型API，使接口更易使用，包括像提供缓存等一些基础功能。\ntools: List[BaseTool]\n对工具的封装，LangChain中对工具的封装是比较简单的，因此保证了比较高的自由度，唯一的要求是输入输出必须是文字形式，def run(self, tool_input: str) -\u003e str。\n自定义Tool只需要3个参数:\nname：工具的标识名称； description: 工具的自然语言描述； func: 功能执行函数，输入输出都为单个的文本。 agent: Agent\n内部使用了一个LLM决定使用什么工具，LangChain中agent的实现有2种，一种是ReACT类型，一种是self-Ask类型，因为后者只能使用qa类型的工具，如果任务涉及不同类型的工具，最好用ReACT类型。其中比较常用的是zero-shot-react-description，其中zero-shot表示推理引导Prompt里不包括示例，description表示LLM在决定调用什么工具的信息都来自于工具的description字段。\n注意，针对特定的任务可以设计针对性的few-shot提升agent的效果。\n介绍完上面的概念，让我们看这个例子是怎么工作的。首先根据提供的工具，agent会生成引导Prompt，对于上面的例子，prompt是下面的样子：\n其中{input}为用户Query的占位符号，{agent_scratchpad}为模型生成填充的位置。下面说明一个循环Thought→Action→Observation→Thought的详细步骤：\n生成Thought，对应的Prompt（只显示Begin!之后的部分）：\nQuestion: Who is Leo DiCaprio’s girlfriend? What is her current age raised to the 0.43 power?\nThought:\nLLM输出：\nI need to find out who Leo DiCaprio’s girlfriend is and then calculate her age raised to the 0.43 power. Action: Search Action Input: “Leo DiCaprio girlfriend”\nObservation:\n其中Observation: 为语言模型生成的终止符。\n根据模型选择的Action，调用Search[ “Leo DiCaprio girlfriend”]得到结果：\nLeonardo DiCaprio has split from girlfriend Camila Morrone. Getty. The Titanic actor hasn’t been in a relationship with a woman over the age of …\n第二次生成Thought，对应的Prompt如下：\nQuestion: Who is Leo DiCaprio’s girlfriend? What is her current age raised to the 0.43 power?Thought: I need to find out who Leo DiCaprio’s girlfriend is and then calculate her age raised to the 0.43 power. Action: Search Action Input: “Leo DiCaprio girlfriend” Observation: Leonardo DiCaprio has split from girlfriend Camila Morrone. Getty. The Titanic actor hasn’t been in a relationship with a woman over the age of … Thought:\n继续这个循环直到输出最终结果，或者超过最大循环次数。\n最后，完整的推理过程如下：\nChatGPT plugin的原理猜想（未完） 根据OpenAI官方的介绍，ChatGPT plugin在设计上要比LangChain精细的多，主要体现：\n每个插件可以有多个API接口； 接口可以定义参数类型和格式； 描述的长度更大； 并且按照描述，对于自定义的新插件使用起来也是zero-shot的方式，所以其实现难度要更高。根据一些相关文献，可以猜想出以下可能的实现方式：\n待补充…\n讨论 应用场景 手机行业\n机器人行业\n对劳动力的影响 Zippia. “23+ Artificial Intelligence And Job Loss Statistics [2023]: How Job Automation Impacts the Workforce” Zippia.com. Feb. 7, 2023, https://www.zippia.com/advice/ai-job-loss-statistics/\n这段内容摘抄自上面这篇博客，作者是一家求职网站的创始人。文中用到的并非严格的统计方法，因此数字有夸大的嫌疑，这里过滤掉一些数字表示的结论，总结出一些未来可能的趋势，供大家参考。\n被AI技术淘汰掉旧的劳动力，不太可能找到更高薪的工作； 从长远来看，AI技术发展对全球经济是有促进作用的。但如果造成大规模的失业潮，就另当别论； 大多数公司会使用不同程度的AI技术来提升效率，也会是AI技术发展最直接的受益者； 当AI技术、机器人替代掉大多数的工作，很多人会没有工作，从而需要政府救济维持生活； 最有可能被取代的工作类型：客服、会计、前台接待、制造类、零售接待、数据分析 等； 最难被取代的工作类型：HR、作家、律师、管理者、科学家、人文类 等； 参考 Welcome to LangChain — 🦜🔗 LangChain 0.0.132 MRKL System 2205.00445.pdf (arxiv.org) REACT: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS Toolformer：*https://arxiv.org/pdf/2302.04761.pdf* ReACT：https://arxiv.org/pdf/2210.03629.pdf YouTube@aiadvantage ",
  "wordCount" : "390",
  "inLanguage": "en",
  "datePublished": "2023-04-07T20:43:43+08:00",
  "dateModified": "2023-04-07T20:43:43+08:00",
  "author":{
    "@type": "Person",
    "name": "Dawson Chen"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:1313/posts/chatgpt-plugin/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "DawsonChen's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:1313/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="DawsonChen&#39;s Blog (Alt + H)">DawsonChen&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://localhost:1313/">Home</a>&nbsp;»&nbsp;<a href="http://localhost:1313/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      ChatGPT Plugins原理介绍和讨论
    </h1>
    <div class="post-meta"><span title='2023-04-07 20:43:43 +0800 CST'>April 7, 2023</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Dawson Chen

      <div  class="meta-item">&nbsp·&nbsp
        <span id="busuanzi_container_page_pv">Pageviews: <span id="busuanzi_value_page_pv"></span></span>
      </div>
    </div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#%e8%83%8c%e6%99%af" aria-label="背景">背景</a><ul>
                        
                <li>
                    <a href="#%e5%bf%85%e8%a6%81%e6%80%a7" aria-label="必要性">必要性</a></li></ul>
                </li>
                <li>
                    <a href="#%e6%a8%a1%e5%9e%8b%e4%bd%bf%e7%94%a8%e5%b7%a5%e5%85%b7%e6%8a%80%e6%9c%af%e5%8f%91%e5%b1%95" aria-label="模型使用工具技术发展">模型使用工具技术发展</a><ul>
                        
                <li>
                    <a href="#%e6%83%b3%e6%b3%95%e7%9a%84%e6%8f%90%e5%87%bamrkl-system" aria-label="想法的提出：MRKL System">想法的提出：MRKL System</a></li>
                <li>
                    <a href="#reasoning%e6%8a%80%e6%9c%afreact" aria-label="Reasoning技术：ReACT">Reasoning技术：ReACT</a></li>
                <li>
                    <a href="#%e4%bd%bf%e7%94%a8%e5%b7%a5%e5%85%b7%e7%9a%84%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8btoolformer" aria-label="使用工具的语言模型：Toolformer">使用工具的语言模型：Toolformer</a></li>
                <li>
                    <a href="#%e5%b7%a5%e5%85%b7%e6%8f%90%e5%87%balangchain" aria-label="工具提出：LangChain">工具提出：LangChain</a></li></ul>
                </li>
                <li>
                    <a href="#chatgpt-plugin%e7%9a%84%e5%8e%9f%e7%90%86" aria-label="ChatGPT plugin的原理">ChatGPT plugin的原理</a><ul>
                        
                <li>
                    <a href="#langchain%e7%9a%84%e5%b7%a5%e4%bd%9c%e6%b5%81%e7%a8%8b" aria-label="LangChain的工作流程">LangChain的工作流程</a></li>
                <li>
                    <a href="#chatgpt-plugin%e7%9a%84%e5%8e%9f%e7%90%86%e7%8c%9c%e6%83%b3%e6%9c%aa%e5%ae%8c" aria-label="ChatGPT plugin的原理猜想（未完）">ChatGPT plugin的原理猜想（未完）</a></li></ul>
                </li>
                <li>
                    <a href="#%e8%ae%a8%e8%ae%ba" aria-label="讨论">讨论</a><ul>
                        
                <li>
                    <a href="#%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af" aria-label="应用场景">应用场景</a></li>
                <li>
                    <a href="#%e5%af%b9%e5%8a%b3%e5%8a%a8%e5%8a%9b%e7%9a%84%e5%bd%b1%e5%93%8d" aria-label="对劳动力的影响">对劳动力的影响</a></li></ul>
                </li>
                <li>
                    <a href="#%e5%8f%82%e8%80%83" aria-label="参考">参考</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h2 id="背景">背景<a hidden class="anchor" aria-hidden="true" href="#背景">#</a></h2>
<p>让我们回顾以下过去的半个月里重要的AI发展。</p>
<table>
<thead>
<tr>
<th>事件</th>
<th>时间</th>
<th>介绍</th>
<th>公司</th>
</tr>
</thead>
<tbody>
<tr>
<td>Visual ChatGPT</td>
<td>3-12</td>
<td>可以通过文本和图片聊天，甚至修改图片内容。</td>
<td>Microsoft</td>
</tr>
<tr>
<td>GPT4发布</td>
<td>3-13</td>
<td>更大的ChatGPT模型，部分专业能力达到人类水平，可以接收图片输入。</td>
<td>OpenAI</td>
</tr>
<tr>
<td>365 Copilot</td>
<td>3-16</td>
<td>智能办公大杀器。</td>
<td>Microsoft</td>
</tr>
<tr>
<td>文心一言</td>
<td>3-16</td>
<td>中国版的ChatGPT</td>
<td>Baidu</td>
</tr>
<tr>
<td>ChatGPT plugin</td>
<td>3-23</td>
<td>可以使用工具的ChatGPT</td>
<td>OpenAI</td>
</tr>
<tr>
<td>HuggingGPT</td>
<td>3-30</td>
<td>可以使用HuggingFace中模型能力的ChatGPT</td>
<td>Microsoft</td>
</tr>
</tbody>
</table>
<p>很多评价说过去的几周是AI发展的Crazy Week，这种速度疯狂到甚至让人们开始担心AI会影响到社会和人类，并在公开信中呼吁暂停AI的研究。造成这种现象的原因可以理解为，一是基于ChatGPT的成功，二是行业内大量的关注。</p>
<p>个人认为，这其中ChatGPT plugin可以认为是对行业应用最有影响力的一个技术，也是继ChatGPT发布以来OpenAI发布的最重要的更新，可以简单的理解为OpenAI发布了对应ChatGPT的应用商店。对未来人工智能应用的形态也有一定启发，以前的AI模型的定位更多的是充当的一个单一的智能工具，具体到某个任务上，还需要人工协同才能完成；但是有了plugin这项技术，那么AI模型可以代替之前人工的部分，自主使用工具，从而端到端的完成某一项任务。这也是为什么一些基础的工作岗位很有可能会被新一代AI技术取代。</p>
<p>在网上已经有很多对ChatGPT plugin如何使用的介绍，但是比较少有对其实现原理进行解析的内容。这篇文章里我们主要分析一下它的原理，以及可能造成的影响。</p>
<h3 id="必要性">必要性<a hidden class="anchor" aria-hidden="true" href="#必要性">#</a></h3>
<p>首先说为什么语言模型要使用插件？随着语言模型的规模不断变大，各种涌现能力被相继发现，从而衍生出各种关于模型能力的研究。但谈到语言模型的应用，始终绕不开一个问题，就是模型无法获取外界的信息。也就是，一旦模型训练完成，后续的所有输出都来自于训练数据中学习到的知识。</p>
<p>大语言模型存在的问题可以总结为以下2点：</p>
<ul>
<li>
<p>缺少最新数据的补充；</p>
<p>在不同的应用场景，对数据的需求也是不同的。在开放问答领域，可以是维基百科一类的数据。在特定业务领域，可能是公司内部的一些私人数据集。</p>
</li>
<li>
<p>缺少专业的能力；</p>
<p>大型语言模型对通用逻辑的理解是比较好的，比方说写一篇文章，与人聊天。但是涉及到特殊的专业，比方说作数学题、求公式的解，这类型问题对模型来说是有点难的。</p>
<p>虽然GPT4号称用了更大的模型，可以在一些专业领域得到类似于人类的效果甚至超越。但是从本质上来看，语言模型所采用的文字接龙训练方式，对于这类问题是非常不友好的。</p>
<p>或许随着模型变大，训练时间更长可以得到更好的效果，但是花费巨大训练出的GPT3在计算能力上远远达不到1970年代出现的计算器，本身就可以说明大模型技术是不足以解决专业推理问题的。</p>
</li>
</ul>
<p>了解了以上模型存在的问题，就可以理解教模型使用插件的必要性了。PS：使用插件、使用工具，在不同的地方有不同的说法，但是是一件事情。</p>
<h2 id="模型使用工具技术发展">模型使用工具技术发展<a hidden class="anchor" aria-hidden="true" href="#模型使用工具技术发展">#</a></h2>
<p>在GPT3发布以后，就有一些AI模型使用插件的技术研究陆续出现，甚至有一些开源的框架在github上收获不错的关注。</p>
<h3 id="想法的提出mrkl-system"><strong>想法的提出：MRKL System</strong><a hidden class="anchor" aria-hidden="true" href="#想法的提出mrkl-system">#</a></h3>
<p>MRKL System（全名是Modular Reasoning, Knowledge and Language，论文<a href="https://arxiv.org/abs/2205.00445">链接</a>，博客<a href="https://www.ai21.com/blog/jurassic-x-crossing-the-neuro-symbolic-chasm-with-the-mrkl-system">链接</a>）由以色列的一家人工智能公司AI21推出，可以被认为是语言模型使用工具系统想法的提出者。虽然在此之前有WebGPT这类教模型使用浏览器的工作，但它是第一个提出将模型作为中枢，接入各种不同类型的插件来完成任务的工作。</p>
<p><img loading="lazy" src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c1c9b7cc490641a2a998832ffd0229ab~tplv-k3u1fbpfcp-watermark.image?" alt="image.png"  />
</p>
<p>从工作流程上来看，MRKL已经完全接近于ChatGPT plugin。MRKL认为这是一种跨越神经学派和符号学派的架构（neuro-symbolic architecture），各种插件可以被认为是符号系统，由神经学派的语言模型进行统一调用。</p>
<p>这篇论文中以使用计算器为例子，主要描述了如何将自然语言中的内容转换为API所需要的参数，文中提出语言模型few-shot在复杂的问题上性能有限，所以用Prompt tuning这种轻量化的微调技术提升转换的准确率。Prompt tuning技术是用特定训练好的非自然语言prompt来控制模型在特定任务中的生成表现，对应到MRKL中那就是每一个插件都需要训练一个特定的Prompt，虽然说有一定训练成本，但也算是一种比较好的解决思路。</p>
<p>可是文中对于最重要的问题：”怎么决定调用插件？“，这块的细节并没有太多的描述，也引出了关于大模型推理技术的发展。</p>
<h3 id="reasoning技术react"><strong>Reasoning技术：ReACT</strong><a hidden class="anchor" aria-hidden="true" href="#reasoning技术react">#</a></h3>
<p>为了教会模型实用工具，一种方法是首先让模型具备推理的能力，从而能够模拟人使用工具的过程。应该说语言模型的训练方式和推理是不沾边的，但是语言模型的美妙之处就在于，当模型大小足够大的时候，它会诞生出很多出乎意料的能力，比方说推理能力。</p>
<p><img loading="lazy" src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f9802e42df4b47b38052f77048cf4bc6~tplv-k3u1fbpfcp-watermark.image?" alt="image.png"  />
</p>
<p>大语言模型的推理能力通过Chain-of-thought体现出来，但是这种推理能力需要显式的Prompt进行引导。根据引导方式的不同产生出各种不同的技术，其本质上是对不同思维方式的模拟，这里我们只介绍比较典型的ReACT技术。</p>
<p>ReACT用强化学习的方式建模推理的过程，agent认为是一个可以使用各种工具的智能体，environment为所有可用插件构成的工具箱集合，action为可以使用的插件功能集合。而控制策略为语言模型中学习到的知识。一个典型的推理的流程如下图所示：</p>
<p><img loading="lazy" src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8a73d01fcff34b82a86d03f2b71fb5c8~tplv-k3u1fbpfcp-watermark.image?" alt="image.png"  />
</p>
<p>ReACT推理流程可以分为Thought→Action→Observation→Thought 这样的循环，具体如何实现在本文的后续内容中会进行分析。</p>
<h3 id="使用工具的语言模型toolformer"><strong>使用工具的语言模型：Toolformer</strong><a hidden class="anchor" aria-hidden="true" href="#使用工具的语言模型toolformer">#</a></h3>
<p>与利用推理能力使用工具的思路不同，Toolformer是在训练语言模型过程中，使模型学习在适当位置调用相关API，并用API结果辅助后续的文本生成。在Toolformer训练过程中，数据是<code>Pittsburgh is also known as [QA(What …?→ Steel City)] the Steel City.</code>这种格式，如果是人去标注数据，首先需要找到API的放置位置，判断标准是API结果对后续文本生成有帮助，并且上文中有API需要的参数；然后是将API的标识、输入、输出以<code>[QA(What …?→ Steel City)]</code>这种形式插入到训练文本中。</p>
<p>注意，模型训练仍然采用典型的文字接龙方式，所以对原本语言模型的能力并没有损失。论文中提出一种利用LLM去自动标注这种数据的方式，和远程监督类似，步骤如下图：</p>
<p><img loading="lazy" src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/40bb5084a59a43d987bc9cd9d5ec1853~tplv-k3u1fbpfcp-watermark.image?" alt="image.png"  />
</p>
<h3 id="工具提出langchain"><strong>工具提出：LangChain</strong><a hidden class="anchor" aria-hidden="true" href="#工具提出langchain">#</a></h3>
<p>LangChain差不多是在2022年底提出的，那时候也是LLMs技术急剧发展的阶段。其核心是做一个基于LLMs的工具，基本上所有需要用LLMs实现的功能都可以在里面找到对应的工具。其中一个主要的能力，就是教会模型使用工具，并且接入方式和扩展性都非常好。除此之外还有很多好用的工具，比如：Prompt管理、Memory。名字中的Chain表示其核心设计思路是将不同的模块链接在一起。</p>
<p>详细的文档见<a href="https://github.com/hwchase17/langchain">链接</a>。</p>
<p><a href="https://github.com/hwchase17/langchain">https://github.com/hwchase17/langchain</a></p>
<p>LangChain中有很多有用的工具，包括各种搜索引擎Bing、Google、SerpAPI（google问答）、wiki等。还有一个更有趣的是Human as a tool插件，可以使语言模型必要时询问人类，从而模拟各种各样的功能。</p>
<p>在原理部分我们会介绍它的工作流程。</p>
<h2 id="chatgpt-plugin的原理">ChatGPT plugin的原理<a hidden class="anchor" aria-hidden="true" href="#chatgpt-plugin的原理">#</a></h2>
<p>ChatGPT plugin是作为一个产品发布的，并且功能还没有完全开放，因此其实现原理细节也不是很清楚。但是由于LangChain中已经实现了类似的功能，并且2者的发布时间比较相近，所以有理由相信2者在原理上是有相似的。</p>
<p>下面我们分2部分，首先分析LangChain中使用工具的原理；第二部分通过比较2者的区别，得出一些关于ChatGPT plugin原理的猜想。</p>
<p><img loading="lazy" src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ece2e5b64a4f40f8a2e4d538f37cdbfe~tplv-k3u1fbpfcp-watermark.image?" alt="image.png"  />
</p>
<h3 id="langchain的工作流程">LangChain的工作流程<a hidden class="anchor" aria-hidden="true" href="#langchain的工作流程">#</a></h3>
<p>首先让我们看一个例子：</p>
<pre tabindex="0"><code>from langchain.agents import load_tools
from langchain.agents import initialize_agent
from langchain.llms import OpenAI

llm = OpenAI(temperature=0)
tools = load_tools([&#34;serpapi&#34;, &#34;llm-math&#34;], llm=llm)
agent = initialize_agent(tools, llm, agent=&#34;zero-shot-react-description&#34;, verbose=True)

response = agent.run(&#34;Who is Leo DiCaprio&#39;s girlfriend? What is her current age raised to the 0.43 power?&#34;)
</code></pre><p>代码里涉及到的关键概念：</p>
<ul>
<li>
<p>llm: BaseLLM</p>
<p>LangChain中对一系列开源模型接口的封装，其主要作用是统一不同的模型API，使接口更易使用，包括像提供缓存等一些基础功能。</p>
</li>
<li>
<p>tools: List[BaseTool]</p>
<p>对工具的封装，LangChain中对工具的封装是比较简单的，因此保证了比较高的自由度，唯一的要求是输入输出必须是文字形式，<code>def run(self, tool_input: str) -&gt; str</code>。</p>
<p>自定义Tool只需要3个参数:</p>
<ul>
<li>name：工具的标识名称；</li>
<li>description: 工具的自然语言描述；</li>
<li>func: 功能执行函数，输入输出都为单个的文本。</li>
</ul>
</li>
<li>
<p>agent: Agent</p>
<p>内部使用了一个LLM决定使用什么工具，LangChain中agent的实现有2种，一种是ReACT类型，一种是self-Ask类型，因为后者只能使用qa类型的工具，如果任务涉及不同类型的工具，最好用ReACT类型。其中比较常用的是<code>zero-shot-react-description</code>，其中zero-shot表示推理引导Prompt里不包括示例，description表示LLM在决定调用什么工具的信息都来自于工具的description字段。</p>
<p>注意，针对特定的任务可以设计针对性的few-shot提升agent的效果。</p>
</li>
</ul>
<p>介绍完上面的概念，让我们看这个例子是怎么工作的。首先根据提供的工具，agent会生成引导Prompt，对于上面的例子，prompt是下面的样子：</p>
<p><img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a1234d5ea48c47838dd4dc8d8477ccca~tplv-k3u1fbpfcp-watermark.image?" alt="image.png"  />
</p>
<p>其中<code>{input}</code>为用户Query的占位符号，<code>{agent_scratchpad}</code>为模型生成填充的位置。下面说明一个循环Thought→Action→Observation→Thought的详细步骤：</p>
<ul>
<li>
<p>生成Thought，对应的Prompt（只显示Begin!之后的部分）：</p>
<blockquote>
<p>Question: Who is Leo DiCaprio&rsquo;s girlfriend? What is her current age raised to the 0.43 power?</p>
<p>Thought:</p>
</blockquote>
</li>
<li>
<p>LLM输出：</p>
<blockquote>
<p>I need to find out who Leo DiCaprio&rsquo;s girlfriend is and then calculate her age raised to the 0.43 power. Action: Search Action Input: &ldquo;Leo DiCaprio girlfriend&rdquo;</p>
<p>Observation:</p>
</blockquote>
<p>其中<code>Observation:</code> 为语言模型生成的终止符。</p>
</li>
<li>
<p>根据模型选择的Action，调用Search[ &ldquo;Leo DiCaprio girlfriend&rdquo;]得到结果：</p>
<blockquote>
<p>Leonardo DiCaprio has split from girlfriend Camila Morrone. Getty. The Titanic actor hasn&rsquo;t been in a relationship with a woman over the age of &hellip;</p>
</blockquote>
</li>
<li>
<p>第二次生成Thought，对应的Prompt如下：</p>
<blockquote>
<p>Question: Who is Leo DiCaprio&rsquo;s girlfriend? What is her current age raised to the 0.43 power?Thought: I need to find out who Leo DiCaprio&rsquo;s girlfriend is and then calculate her age raised to the 0.43 power. Action: Search Action Input: &ldquo;Leo DiCaprio girlfriend&rdquo; Observation: Leonardo DiCaprio has split from girlfriend Camila Morrone. Getty. The Titanic actor hasn&rsquo;t been in a relationship with a woman over the age of &hellip; Thought:</p>
</blockquote>
</li>
<li>
<p>继续这个循环直到输出最终结果，或者超过最大循环次数。</p>
</li>
</ul>
<p>最后，完整的推理过程如下：</p>
<p><img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/403cd9564d10443cb850f3ef086a307b~tplv-k3u1fbpfcp-watermark.image?" alt="image.png"  />
</p>
<h3 id="chatgpt-plugin的原理猜想未完">ChatGPT plugin的原理猜想（未完）<a hidden class="anchor" aria-hidden="true" href="#chatgpt-plugin的原理猜想未完">#</a></h3>
<p>根据OpenAI官方的介绍，ChatGPT plugin在设计上要比LangChain精细的多，主要体现：</p>
<ul>
<li>每个插件可以有多个API接口；</li>
<li>接口可以定义参数类型和格式；</li>
<li>描述的长度更大；</li>
</ul>
<p>并且按照描述，对于自定义的新插件使用起来也是zero-shot的方式，所以其实现难度要更高。根据一些相关文献，可以猜想出以下可能的实现方式：</p>
<p>待补充…</p>
<h2 id="讨论">讨论<a hidden class="anchor" aria-hidden="true" href="#讨论">#</a></h2>
<h3 id="应用场景">应用场景<a hidden class="anchor" aria-hidden="true" href="#应用场景">#</a></h3>
<p>手机行业</p>
<p>机器人行业</p>
<h3 id="对劳动力的影响">对劳动力的影响<a hidden class="anchor" aria-hidden="true" href="#对劳动力的影响">#</a></h3>
<p>Zippia. &ldquo;23+ Artificial Intelligence And Job Loss Statistics [2023]: How Job Automation Impacts the Workforce&rdquo; <a href="http://zippia.com/">Zippia.com</a>. Feb. 7, 2023, <a href="https://www.zippia.com/advice/ai-job-loss-statistics/">https://www.zippia.com/advice/ai-job-loss-statistics/</a></p>
<p>这段内容摘抄自上面这篇博客，作者是一家求职网站的创始人。文中用到的并非严格的统计方法，因此数字有夸大的嫌疑，这里过滤掉一些数字表示的结论，总结出一些未来可能的趋势，供大家参考。</p>
<ul>
<li>被AI技术淘汰掉旧的劳动力，不太可能找到更高薪的工作；</li>
<li>从长远来看，AI技术发展对全球经济是有促进作用的。但如果造成大规模的失业潮，就另当别论；</li>
<li>大多数公司会使用不同程度的AI技术来提升效率，也会是AI技术发展最直接的受益者；</li>
<li>当AI技术、机器人替代掉大多数的工作，很多人会没有工作，从而需要政府救济维持生活；</li>
<li>最有可能被取代的工作类型：客服、会计、前台接待、制造类、零售接待、数据分析 等；</li>
<li>最难被取代的工作类型：HR、作家、律师、管理者、科学家、人文类 等；</li>
</ul>
<h2 id="参考">参考<a hidden class="anchor" aria-hidden="true" href="#参考">#</a></h2>
<ol>
<li><a href="https://python.langchain.com/en/latest/">Welcome to LangChain — 🦜🔗 LangChain 0.0.132</a></li>
<li>MRKL System <a href="https://arxiv.org/pdf/2205.00445.pdf">2205.00445.pdf (arxiv.org)</a></li>
<li>REACT: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS</li>
<li>Toolformer：<a href="https://arxiv.org/pdf/2302.04761.pdf">*</a><a href="https://arxiv.org/pdf/2302.04761.pdf*">https://arxiv.org/pdf/2302.04761.pdf*</a></li>
<li>ReACT：<a href="https://arxiv.org/pdf/2210.03629.pdf">https://arxiv.org/pdf/2210.03629.pdf</a></li>
<li><a href="https://www.youtube.com/@aiadvantage">YouTube@aiadvantage</a></li>
</ol>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
<nav class="paginav">
  <a class="prev" href="http://localhost:1313/posts/mixture-training/">
    <span class="title">« Prev</span>
    <br>
    <span>混合精度训练</span>
  </a>
</nav>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share ChatGPT Plugins原理介绍和讨论 on x"
            href="https://x.com/intent/tweet/?text=ChatGPT%20Plugins%e5%8e%9f%e7%90%86%e4%bb%8b%e7%bb%8d%e5%92%8c%e8%ae%a8%e8%ae%ba&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fchatgpt-plugin%2f&amp;hashtags=">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share ChatGPT Plugins原理介绍和讨论 on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fchatgpt-plugin%2f&amp;title=ChatGPT%20Plugins%e5%8e%9f%e7%90%86%e4%bb%8b%e7%bb%8d%e5%92%8c%e8%ae%a8%e8%ae%ba&amp;summary=ChatGPT%20Plugins%e5%8e%9f%e7%90%86%e4%bb%8b%e7%bb%8d%e5%92%8c%e8%ae%a8%e8%ae%ba&amp;source=http%3a%2f%2flocalhost%3a1313%2fposts%2fchatgpt-plugin%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share ChatGPT Plugins原理介绍和讨论 on reddit"
            href="https://reddit.com/submit?url=http%3a%2f%2flocalhost%3a1313%2fposts%2fchatgpt-plugin%2f&title=ChatGPT%20Plugins%e5%8e%9f%e7%90%86%e4%bb%8b%e7%bb%8d%e5%92%8c%e8%ae%a8%e8%ae%ba">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share ChatGPT Plugins原理介绍和讨论 on facebook"
            href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fposts%2fchatgpt-plugin%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share ChatGPT Plugins原理介绍和讨论 on whatsapp"
            href="https://api.whatsapp.com/send?text=ChatGPT%20Plugins%e5%8e%9f%e7%90%86%e4%bb%8b%e7%bb%8d%e5%92%8c%e8%ae%a8%e8%ae%ba%20-%20http%3a%2f%2flocalhost%3a1313%2fposts%2fchatgpt-plugin%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share ChatGPT Plugins原理介绍和讨论 on telegram"
            href="https://telegram.me/share/url?text=ChatGPT%20Plugins%e5%8e%9f%e7%90%86%e4%bb%8b%e7%bb%8d%e5%92%8c%e8%ae%a8%e8%ae%ba&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fchatgpt-plugin%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share ChatGPT Plugins原理介绍和讨论 on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=ChatGPT%20Plugins%e5%8e%9f%e7%90%86%e4%bb%8b%e7%bb%8d%e5%92%8c%e8%ae%a8%e8%ae%ba&u=http%3a%2f%2flocalhost%3a1313%2fposts%2fchatgpt-plugin%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="http://localhost:1313/">DawsonChen&#39;s Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>

        
    <div class="busuanzi-footer">
    <span id="busuanzi_container_site_pv">
        Page Views<span id="busuanzi_value_site_pv"></span>次
    </span>
    <span id="busuanzi_container_site_uv">
        Unique Visitors<span id="busuanzi_value_site_uv"></span>人次
    </span>
    </div></footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
