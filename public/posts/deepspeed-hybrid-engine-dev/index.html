<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>Deepspeed-HybridEngine开发指南 | DawsonChen&#39;s Blog</title>
<meta name="keywords" content="">
<meta name="description" content="2023-11-29写； 2023-12-06修改：增加适配模型开发流程说明；增加bug解决记录； Deepspeed-Chat是一个优秀且易用的PPO开源实现，实际在使用时HybridEngine开发是PPO工程相关的重要一环，本次分享的目的：
了解整体Deepspeed的架构，和代码逻辑； 清楚如何在Deepspeed上进行HE适配相关开发； 主要是对新的模型结构的适配； 先回答为什么需要做适配，因为HE(hybrid engine)本身解决的问题是将训练中的zero3模型，转换成更高效的对设备通讯压力不大的推理模式，可以是不带tp的全参数推理，也可以是带tp的推理。所以不管是哪种形式的推理，都需要重构推理图，并且处理好这种模式转换间设计的大量引用，也是适配需要做的全部事情。虽然我相信这个过程一定可以改成完全自动的形式，但是目前还没有找到这种实现方式。
然后看一下HE的优势是什么，推理速度不用说，就相当于带或不带zero3的差距，通常10x左右。还有一个优势是带TP的HE方式在内存上的优势，这一点在模型比较大且显存压力较大的场景下尤为重要。下面举ppo的例子，如果训练的sft和actor模型大小是70b，reward和critic是7b，一共4个模型，考虑32张A100-80G的场景：
ZeRO3训练模型占用显存（每张卡）：
Actor: (优化器12 &#43; 参数2 &#43; 梯度2) * 70 / 32 = 35G SFT：通常offload，显存可以记作0G reward&#43;critic：3.9G 每张卡总共需要：38.9G
占用的显存是够的，但是zero3推理速度在ppo生成阶段几乎不可用；
（HE模式）ZeRO3训练模型&#43;TP推理占用显存（每张卡）：
TP的size设为8
训练阶段：TP的参数释放掉，和ZeRO3模式一样，38.9G； 生成阶段：70 * 2 = 140G（全部推理参数），TP参数切片140 / 8 = 17.5G，所以一共需要56.4G； 训练用ZeRO3节约显存，生成用HE提升速度。如果不用TP的HE那么140G放到一张卡上，目前还没有设备能支持。
1. 整体架构 1.1 启动流程 涉及代码都在deepspeed/launcher目录下面，一共2个文件 runner和launcher。
1.2 Zero3 zero3架构是什么样的，如何实现？
https://github.com/microsoft/DeepSpeed/blob/2c2a7f31bcc20ae12ce8d2b8af14448939ebdf12/deepspeed/runtime/zero/stage3.py#L120C9-L120C9
自动对参数进行all_gather，使用后自动释放；实现核心 ZeROOrderedDict
1.3 Hybrid Engine 为什么需要HE？
Zero3是用来训练的并行方式，推理的时候有很大劣势，并且不能扩展到多机的情况。
HE如何起到作用？实现方式？
HE内容：1. 自定义算子；2. tensor parallelism；
不带TP的方式； 适用于 7b、13b 单机多卡 带TP的方式； 适用于66b、70b 更大模型的训练 比如说模型ChatGLM2，它的代码实现里transformer块对应的实现类是 GLMBlock，HE就是实现一个新的推理过程，带或者不带TP区别就是这个推理过程是不是分布式，然后替换掉 GLMBlock的forward方法。">
<meta name="author" content="">
<link rel="canonical" href="http://localhost:1313/posts/deepspeed-hybrid-engine-dev/">
<meta name="google-site-verification" content="XYZabc">
<meta name="yandex-verification" content="XYZabc">
<meta name="msvalidate.01" content="XYZabc">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/posts/deepspeed-hybrid-engine-dev/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.css"
    integrity="sha384-bYdxxUwYipFNohQlHt0bjN/LCpueqWz13HufFEV1SUatKs1cm4L6fFgCi1jT643X" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.js"
    integrity="sha384-Qsn9KnoKISj6dI8g7p1HBlNpVx0I8p1SvlwOldgi3IorMle61nQy4zEahWYtljaz"
    crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/auto-render.min.js"
    integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05"
    crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        renderMathInElement(document.body, {
            
            
            delimiters: [
                { left: '$$', right: '$$', display: true },
                { left: '$', right: '$', display: false },
                { left: '\\(', right: '\\)', display: false },
                { left: '\\[', right: '\\]', display: true }
            ],
            
            throwOnError: false
        });
    });
</script>



<script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
<script>

const config = {
    startOnLoad:true,
    theme: 'forest',
    themeVariables: {
        lineColor: "#fafafa"    
    },
    flowchart: {
        useMaxWidth:false,
        htmlLabels:true
        }
};
mermaid.initialize(config);


window.onload = () => {
    window.mermaid.init(undefined, document.querySelectorAll('.language-mermaid'));
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="DawsonChen&#39;s Blog (Alt + H)">DawsonChen&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Deepspeed-HybridEngine开发指南
      <span class="entry-hint" title="Draft">
        <svg xmlns="http://www.w3.org/2000/svg" height="35" viewBox="0 -960 960 960" fill="currentColor">
          <path
            d="M160-410v-60h300v60H160Zm0-165v-60h470v60H160Zm0-165v-60h470v60H160Zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22q0 11-4.5 22.5T862.09-380L643-160H520Zm300-263-37-37 37 37ZM580-220h38l121-122-18-19-19-18-122 121v38Zm141-141-19-18 37 37-18-19Z" />
        </svg>
      </span>
    </h1>
    <div class="post-meta"><span title='2024-01-07 12:37:45 +0800 CST'>January 7, 2024</span>&nbsp;|&nbsp;<a href="https://github.com/%3cpath_to_repo%3e/content/posts/deepspeed-hybrid-engine-dev.md" rel="noopener noreferrer" target="_blank">Suggest Changes</a>

</div>
  </header> 
  <div class="post-content"><ul>
<li><em>2023-11-29写；</em></li>
<li><em>2023-12-06修改：增加适配模型开发流程说明；增加bug解决记录；</em></li>
</ul>
<p>Deepspeed-Chat是一个优秀且易用的PPO开源实现，实际在使用时HybridEngine开发是PPO工程相关的重要一环，本次分享的目的：</p>
<ul>
<li>了解整体Deepspeed的架构，和代码逻辑；</li>
<li>清楚如何在Deepspeed上进行HE适配相关开发；
<ul>
<li>主要是对新的模型结构的适配；</li>
</ul>
</li>
</ul>
<p>先回答为什么需要做适配，因为HE(hybrid engine)本身解决的问题是将训练中的zero3模型，转换成更高效的对设备通讯压力不大的推理模式，可以是不带tp的全参数推理，也可以是带tp的推理。所以不管是哪种形式的推理，都需要重构推理图，并且处理好这种模式转换间设计的大量引用，也是适配需要做的全部事情。虽然我相信这个过程一定可以改成完全自动的形式，但是目前还没有找到这种实现方式。</p>
<p>然后看一下HE的优势是什么，推理速度不用说，就相当于带或不带zero3的差距，通常10x左右。还有一个优势是带TP的HE方式在内存上的优势，这一点在模型比较大且显存压力较大的场景下尤为重要。下面举ppo的例子，如果训练的sft和actor模型大小是70b，reward和critic是7b，一共4个模型，考虑32张A100-80G的场景：</p>
<ul>
<li>
<p>ZeRO3训练模型占用显存（每张卡）：</p>
<p>Actor: (优化器12 + 参数2 + 梯度2) * 70 / 32 = 35G
SFT：通常offload，显存可以记作0G
reward+critic：3.9G
每张卡总共需要：38.9G</p>
<p>占用的显存是够的，但是zero3推理速度在ppo生成阶段几乎不可用；</p>
</li>
<li>
<p>（HE模式）ZeRO3训练模型+TP推理占用显存（每张卡）：</p>
<p>TP的size设为8</p>
<ul>
<li>训练阶段：TP的参数释放掉，和ZeRO3模式一样，38.9G；</li>
<li>生成阶段：70 * 2 = 140G（全部推理参数），TP参数切片140 / 8 = 17.5G，所以一共需要56.4G；</li>
</ul>
<p>训练用ZeRO3节约显存，生成用HE提升速度。如果不用TP的HE那么140G放到一张卡上，目前还没有设备能支持。</p>
</li>
</ul>
<h2 id="1-整体架构">1. 整体架构<a hidden class="anchor" aria-hidden="true" href="#1-整体架构">#</a></h2>
<h3 id="11-启动流程">1.1 启动流程<a hidden class="anchor" aria-hidden="true" href="#11-启动流程">#</a></h3>
<p>涉及代码都在deepspeed/launcher目录下面，一共2个文件 runner和launcher。</p>
<p><img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/734b04c4a96c410fa9e942080b574297~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1598&amp;h=1068&amp;s=815712&amp;e=png&amp;b=fbfafa" alt="image.png"  />
</p>
<h3 id="12-zero3">1.2 Zero3<a hidden class="anchor" aria-hidden="true" href="#12-zero3">#</a></h3>
<ul>
<li>
<p><input checked="" disabled="" type="checkbox"> zero3架构是什么样的，如何实现？</p>
<p><a href="https://github.com/microsoft/DeepSpeed/blob/2c2a7f31bcc20ae12ce8d2b8af14448939ebdf12/deepspeed/runtime/zero/stage3.py#L120C9-L120C9">https://github.com/microsoft/DeepSpeed/blob/2c2a7f31bcc20ae12ce8d2b8af14448939ebdf12/deepspeed/runtime/zero/stage3.py#L120C9-L120C9</a></p>
<p>自动对参数进行all_gather，使用后自动释放；实现核心 <code>ZeROOrderedDict</code></p>
</li>
</ul>
<h3 id="13-hybrid-engine">1.3 Hybrid Engine<a hidden class="anchor" aria-hidden="true" href="#13-hybrid-engine">#</a></h3>
<ul>
<li>
<p><input checked="" disabled="" type="checkbox"> 为什么需要HE？</p>
<p>Zero3是用来训练的并行方式，推理的时候有很大劣势，并且不能扩展到多机的情况。</p>
</li>
<li>
<p><input checked="" disabled="" type="checkbox"> HE如何起到作用？实现方式？</p>
<p>HE内容：1. 自定义算子；2. tensor parallelism；</p>
<ul>
<li><input checked="" disabled="" type="checkbox"> 不带TP的方式； 适用于 7b、13b  单机多卡</li>
<li><input checked="" disabled="" type="checkbox"> 带TP的方式； 适用于66b、70b 更大模型的训练</li>
</ul>
<p>比如说模型ChatGLM2，它的代码实现里transformer块对应的实现类是 <code>GLMBlock</code>，HE就是实现一个新的推理过程，带或者不带TP区别就是这个推理过程是不是分布式，然后替换掉 <code>GLMBlock</code>的forward方法。</p>
<p>这种替换方式就像下面这个例子：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Bird</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">move</span><span class="p">(</span><span class="bp">self</span><span class="p">,):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;i</span><span class="se">\&#39;</span><span class="s1">m flying&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Pig</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">move</span><span class="p">(</span><span class="bp">self</span><span class="p">,):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;i</span><span class="se">\&#39;</span><span class="s1">m walking&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">bird</span> <span class="o">=</span> <span class="n">Bird</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">pig</span> <span class="o">=</span> <span class="n">Pig</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">pig</span><span class="o">.</span><span class="n">move</span> <span class="o">=</span> <span class="n">bird</span><span class="o">.</span><span class="n">move</span>
</span></span><span class="line"><span class="cl"><span class="n">pig</span><span class="o">.</span><span class="n">move</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="s1">&#39;&#39;&#39; output
</span></span></span><span class="line"><span class="cl"><span class="s1">&gt;&gt;&gt; i&#39;m flying
</span></span></span><span class="line"><span class="cl"><span class="s1">&#39;&#39;&#39;</span>
</span></span></code></pre></div><p>在python里，Pig想要飞的方式是借用Bird的翅膀，而不需要通过继承实现。</p>
</li>
</ul>
<h4 id="运作流程">运作流程<a hidden class="anchor" aria-hidden="true" href="#运作流程">#</a></h4>
<p>Container、Inference、Module、ops之间的调用关系；</p>
<p><img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2fe6046f1bf14d2e9cb26a71ef2a2820~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1562&amp;h=686&amp;s=529564&amp;e=png&amp;b=fafafa" alt="image.png"  />
</p>
<p>HE运作流程，有2个部分：</p>
<ol>
<li>
<p>初始化，module到Continer的创建流程；</p>
<ol>
<li>policy定义的位置；
入口：hybrid_engine.py populate_all_inference_policies
policy定义文件：deepspeed/module_inject/replace_policy.py
policy和container对应关系：deepspeed/module_inject/utils.py</li>
<li>Container创建过程； <br>
<img loading="lazy" src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6daedac42b1c4f28b26ca796fd415589~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1352&amp;h=624&amp;s=243160&amp;e=png&amp;b=202020" alt="image.png"  />

<ol>
<li>Create_module 创建推理图；新的forward函数</li>
<li>set_params_wo_copy  container将模型变量赋值给计算图；只给引用 不复制</li>
<li>forward的替换发生在eval方法里；</li>
</ol>
</li>
<li>计算图的构建；
<ol>
<li>保证和原生pytorch的计算过程保持一致；</li>
<li>尽量使用ds提前定义的cuda算子；</li>
</ol>
</li>
</ol>
</li>
<li>
<p>generate的过程；</p>
<p><img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/355b14a0493a486098c522d85d597a79~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1544&amp;h=946&amp;s=979702&amp;e=png&amp;b=faf9f9" alt="image.png"  />
</p>
</li>
</ol>
<h2 id="2-如何适配新的模型">2. 如何适配新的模型<a hidden class="anchor" aria-hidden="true" href="#2-如何适配新的模型">#</a></h2>
<h3 id="21-关键点">2.1 关键点<a hidden class="anchor" aria-hidden="true" href="#21-关键点">#</a></h3>
<p>以chatglm2和BlueLM为例，几个关键点：</p>
<ol>
<li>
<p>如何定义一个新的模型；
参考HE的架构，主要新增policy、container，以及使用对应的ops重构计算图；</p>
<ol>
<li>Policy：
<ol>
<li>定义原模型中关键的参数变量；</li>
<li>定义原模型中的参数引用；</li>
<li>定义要替换的模块，一般为transformer层级模块对应的类；</li>
</ol>
</li>
<li>Container；
<ol>
<li>保存计算图中需要的参数tensor引用；</li>
<li>生成推理用的module，用module.forward替换掉原模块中的forward；</li>
</ol>
</li>
<li>重构推理计算图；
<ol>
<li>检查算子是否可以复用；</li>
<li>检查结果是否正确；</li>
</ol>
</li>
</ol>
</li>
<li>
<p>TP相关的代码；</p>
<p>改动代码之前，请阅读<a href="https://arxiv.org/pdf/1909.08053.pdf">arxiv.org/pdf/1909.08053.pdf</a>论文，了解Tensor Parallelism的大模型分布式训练方式。在HE中只关注前向推理的流程，适配时最主要的是确定好参数切分的方式。</p>
<ol>
<li>参数复制，拆分；</li>
<li>推理时的reduce操作；</li>
</ol>
</li>
<li>
<p>计算流程实现；</p>
</li>
<li>
<p>*Inference相关的代码；</p>
<p>chatglm2 66b 8卡推理；</p>
</li>
</ol>
<h3 id="22-适配开发流程">2.2 适配开发流程<a hidden class="anchor" aria-hidden="true" href="#22-适配开发流程">#</a></h3>
<p>HE本质上就是用zero3参数收集起来，重新生成一个计算图（container.module.forward函数）复现并替换原pytorch模型的推理结果；</p>
<ol>
<li>
<p>找到要替换的类，policy对应的类；
一般在要适配的模型定义文件里面；</p>
</li>
<li>
<p>找到container.module.forward调用入口；
在替换模型定义文件里，policy对应的类的forward函数的调用入口，注意入口的参数传递和container对应的forward声明对齐；</p>
</li>
<li>
<p>检查点：</p>
<ul>
<li><input checked="" disabled="" type="checkbox"> 参数引用是否正确；</li>
<li><input checked="" disabled="" type="checkbox"> 计算流程是否一致；</li>
</ul>
</li>
<li>
<p>单步调试；
每一步的计算和pytorch代码是否一致；</p>
</li>
</ol>
<ul>
<li><input checked="" disabled="" type="checkbox"> TP代码开发的区别：
<ul>
<li>container需要单独保存参数；
原始参数的切片；</li>
<li>在生成阶段，需要先准备tp参数；更重要的是，在生成结束之后要及时释放tp的参数；
在container的有相应的方法需要实现，主要有参数准备、参数释放；</li>
<li>计算阶段需要适配tp流程；
显然的变化是，计算用的weight的大小会改变；</li>
<li>注意：generate阶段需要对输入进行拼接；</li>
</ul>
</li>
</ul>
<h3 id="23-单元测试方法">2.3 单元测试方法<a hidden class="anchor" aria-hidden="true" href="#23-单元测试方法">#</a></h3>
<ul>
<li>
<p><input checked="" disabled="" type="checkbox"> 如何进行多机程序的debug；</p>
<p>主要难点是多机程序的调试，这里提供2种方式；</p>
<ol>
<li>
<p>可以使用pdb在单节点上进行调试代码；代码如下：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">## 在需要阻塞的位置插入下面的代码</span>
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="n">dist</span><span class="o">.</span><span class="n">get_rank</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>   <span class="c1"># 判断是否为0的进程</span>
</span></span><span class="line"><span class="cl">    <span class="n">breakpoint</span><span class="p">()</span>   <span class="c1"># 断点</span>
</span></span><span class="line"><span class="cl"><span class="n">dist</span><span class="o">.</span><span class="n">barrier</span><span class="p">()</span>  <span class="c1"># 当0进程阻塞时，其他节点进行等待</span>
</span></span></code></pre></div></li>
<li>
<p>（理论可行，未做尝试）用单进程模拟多进程；</p>
<p>deepspeed启动命令中提供了 <code>--force_multi</code>参数，使单进程可以用来模拟多进程，并在vscode中配置启动命令用deepspeed，这样可以使用vscode进行单步调试。</p>
</li>
</ol>
<p>pdb的了解和相关命令查看<a href="https://docs.python.org/zh-cn/3/library/pdb.html">pdb &mdash; Python 的调试器 — Python 3.12.0 文档</a>。</p>
</li>
<li>
<p><input checked="" disabled="" type="checkbox"> 调试程序如何写；</p>
<p>参考deepspeed/tests/下面对应的文件，比如：test_ds_bluelm.py。</p>
</li>
</ul>
<h2 id="3-开发中bugs解决过程">3. 开发中BUGs解决过程<a hidden class="anchor" aria-hidden="true" href="#3-开发中bugs解决过程">#</a></h2>
<h3 id="inflight状态异常">INFLIGHT状态异常<a hidden class="anchor" aria-hidden="true" href="#inflight状态异常">#</a></h3>
<p><em>耗时：2天</em></p>
<ul>
<li>
<p><input checked="" disabled="" type="checkbox"> INFLIGHT状态参数出现异常，解决思路：</p>
<ul>
<li>
<p><input checked="" disabled="" type="checkbox"> 验证inflight状态出现的时机；</p>
<ul>
<li>
<p><input checked="" disabled="" type="checkbox"> 分别在生成训练之后打印参数的状态；</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-text" data-lang="text"><span class="line"><span class="cl">第1次生成...
</span></span><span class="line"><span class="cl">Counter({&lt;ZeroParamStatus.NOT_AVAILABLE: 2&gt;: 925})
</span></span><span class="line"><span class="cl">第1次生成...
</span></span><span class="line"><span class="cl">第1次训练...
</span></span><span class="line"><span class="cl">Counter({&lt;ZeroParamStatus.NOT_AVAILABLE: 2&gt;: 762, &lt;ZeroParamStatus.AVAILABLE: 1&gt;: 163})
</span></span><span class="line"><span class="cl">第1次训练...
</span></span><span class="line"><span class="cl">第2次生成...
</span></span><span class="line"><span class="cl">Counter({&lt;ZeroParamStatus.NOT_AVAILABLE: 2&gt;: 758, &lt;ZeroParamStatus.AVAILABLE: 1&gt;: 163, &lt;ZeroParamStatus.INFLIGHT: 3&gt;: 4})
</span></span><span class="line"><span class="cl">发生报错
</span></span></code></pre></div><p>流程如上面的记录，在第二次训练的时候有参数没有释放；</p>
</li>
<li>
<p><input checked="" disabled="" type="checkbox"> 查看训练过程中，AVAILABLE状态的变量有哪些？</p>
<ul>
<li>
<p><input checked="" disabled="" type="checkbox"> Available 变量：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="s1">&#39;model.layers.x.self_attn.k_proj.lora_left_weight&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"> <span class="s1">&#39;model.layers.x.self_attn.v_proj.lora_left_weight&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"> <span class="s1">&#39;model.layers.x.input_layernorm.weight&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"> <span class="s1">&#39;model.layers.x.post_attention_layernorm.weight&#39;</span>
</span></span><span class="line"><span class="cl"><span class="mi">40</span><span class="n">层</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">=</span> <span class="mi">160</span><span class="n">个</span> 
</span></span><span class="line"><span class="cl"> <span class="s1">&#39;model.norm.weight&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"> <span class="s1">&#39;model.embed_layer_norm.weight&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"> <span class="s1">&#39;model.embed_layer_norm.bias&#39;</span>
</span></span><span class="line"><span class="cl"><span class="mi">3</span><span class="n">个</span>
</span></span></code></pre></div></li>
<li>
<p><input checked="" disabled="" type="checkbox"> Inflight 变量</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="s1">&#39;model.layers.39.self_attn.q_proj.weight&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"> <span class="s1">&#39;model.layers.39.self_attn.q_proj.lora_right_weight&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"> <span class="s1">&#39;model.layers.39.self_attn.q_proj.lora_left_weight&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"> <span class="s1">&#39;model.layers.39.self_attn.k_proj.weight&#39;</span>
</span></span></code></pre></div></li>
</ul>
<p>大概率和lora是有关系的，从这里下手找原因；</p>
</li>
<li>
<p><input checked="" disabled="" type="checkbox"> 修复container中lora参数的bug；</p>
</li>
<li>
<p><input checked="" disabled="" type="checkbox"> 修复mlp参数中lora没有起作用；</p>
</li>
<li>
<p><input checked="" disabled="" type="checkbox"> 修复mlp和attention中参数拷贝的bug；</p>
<ul>
<li><input checked="" disabled="" type="checkbox"> BlueLMAttention细节：
<ul>
<li>self.attn_qkvw 需要等于None；</li>
<li>self.attn_qw, self.attn_kw, self.attn_vw 在推理过程中合并成qkvw；
使用提前开辟好内存的方式</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>==修复lora相关代码后，问题仍然存在。==</p>
</li>
<li>
<p><input checked="" disabled="" type="checkbox"> 测试glm2-6b用zero3训练的时候，参数状态变化情况；</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">生成阶段</span>
</span></span><span class="line"><span class="cl"><span class="n">Counter</span><span class="p">({</span><span class="o">&lt;</span><span class="n">ZeroParamStatus</span><span class="o">.</span><span class="n">NOT_AVAILABLE</span><span class="p">:</span> <span class="mi">2</span><span class="o">&gt;</span><span class="p">:</span> <span class="mi">423</span><span class="p">})</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">训练阶段</span>
</span></span><span class="line"><span class="cl"><span class="n">Counter</span><span class="p">({</span><span class="o">&lt;</span><span class="n">ZeroParamStatus</span><span class="o">.</span><span class="n">NOT_AVAILABLE</span><span class="p">:</span> <span class="mi">2</span><span class="o">&gt;</span><span class="p">:</span> <span class="mi">338</span><span class="p">,</span> <span class="o">&lt;</span><span class="n">ZeroParamStatus</span><span class="o">.</span><span class="n">AVAILABLE</span><span class="p">:</span> <span class="mi">1</span><span class="o">&gt;</span><span class="p">:</span> <span class="mi">85</span><span class="p">})</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">训练后第一次生成阶段</span>
</span></span><span class="line"><span class="cl"><span class="n">Counter</span><span class="p">({</span><span class="o">&lt;</span><span class="n">ZeroParamStatus</span><span class="o">.</span><span class="n">NOT_AVAILABLE</span><span class="p">:</span> <span class="mi">2</span><span class="o">&gt;</span><span class="p">:</span> <span class="mi">337</span><span class="p">,</span> <span class="o">&lt;</span><span class="n">ZeroParamStatus</span><span class="o">.</span><span class="n">AVAILABLE</span><span class="p">:</span> <span class="mi">1</span><span class="o">&gt;</span><span class="p">:</span> <span class="mi">85</span><span class="p">,</span> <span class="o">&lt;</span><span class="n">ZeroParamStatus</span><span class="o">.</span><span class="n">INFLIGHT</span><span class="p">:</span> <span class="mi">3</span><span class="o">&gt;</span><span class="p">:</span> <span class="mi">1</span><span class="p">})</span>
</span></span><span class="line"><span class="cl"><span class="p">[</span><span class="s1">&#39;transformer.encoder.layers.0.input_layernorm.weight&#39;</span><span class="p">,</span> <span class="s1">&#39;transformer.encoder.layers.0.self_attention.query_key_value.bias&#39;</span><span class="p">,</span> <span class="s1">&#39;transformer.encoder.layers.0.post_attention_layernorm.weight&#39;</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl"> <span class="o">...</span> <span class="c1"># 每一层</span>
</span></span><span class="line"><span class="cl"> <span class="s1">&#39;transformer.encoder.final_layernorm.weight&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="p">[</span><span class="s1">&#39;transformer.encoder.layers.27.mlp.dense_4h_to_h.weight&#39;</span><span class="p">]</span>
</span></span></code></pre></div><p>和bluelm测试的效果差不多，但是glm6b可以正常训练；</p>
<ul>
<li>
<p><input checked="" disabled="" type="checkbox"> 检查glm6b的代码有什么区别；</p>
<ul>
<li>训练脚本； <!-- raw HTML omitted -->gradient checkpoint、offload不一致<!-- raw HTML omitted --></li>
<li>container 参数复制；</li>
</ul>
<p>==去掉gradient checkpoint之后可以正常训练；==</p>
</li>
</ul>
</li>
<li>
<p><input disabled="" type="checkbox"> <del>梳理zero3过程，找到为什么会出现inflight状态，以及对应的意义；</del></p>
<ul>
<li><input disabled="" type="checkbox"> <del>AVAILABLE 和 INFLIGHT 状态转换图</del></li>
<li><input disabled="" type="checkbox"> <del>INFLIGHT # parameters are being gathered.</del></li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="显存超出bug">显存超出bug<a hidden class="anchor" aria-hidden="true" href="#显存超出bug">#</a></h3>
<p><em>耗时：一天</em></p>
<ul>
<li>
<p><input checked="" disabled="" type="checkbox"> 显存超出BUG解决；</p>
<ul>
<li><input checked="" disabled="" type="checkbox"> 原因分析：显存workspace申请不够，导致在使用算子计算softmax的时候超出限制；</li>
<li><input checked="" disabled="" type="checkbox"> 解决方法如下：
<ol>
<li>修改自定义算子申请显存的逻辑；
代码在csrc/transformer/inference/includes/inference_context.h#L98 GenWorkSpace函数里</li>
<li><del>调大ds_bluelm.py里面申请显存的参数；</del>
<del>代码在deepspeed/model_implementations/transformers/ds_bluelm.py</del></li>
<li>BlueLMAttention里forward计算attention的部分改成pytorch实现；
pytorch动态申请显存，只要显存够就不存在溢出的风险；</li>
</ol>
</li>
</ul>
</li>
<li>
<p><input checked="" disabled="" type="checkbox"> 第2种方法，通过调大长度参数，仍然没有解决；</p>
</li>
<li>
<p><input checked="" disabled="" type="checkbox"> 第3种方法，使用pytorch重新定义attention计算过程；</p>
<ul>
<li>
<p><input checked="" disabled="" type="checkbox"> kv-cache适配时，遇到present_key_value向量无理由自发改变的问题；</p>
<p><img loading="lazy" src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1a825d9e1be5458c9ee0d59295d550cc~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=1342&amp;h=780&amp;s=330582&amp;e=png&amp;b=1f1f1f" alt="image.png"  />
</p>
<p>通过改变present_key_value内存地址解决；==原因未知，如果有，就是对cuda敬畏之心不够！==</p>
</li>
</ul>
</li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="http://localhost:1313/">DawsonChen&#39;s Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
